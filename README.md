# ðŸ“ˆ Robustness Analysis of Pareto-based Joint Evaluation of Fairness and Relevance in Recommender Systems âš–

This repository contains the code for the _extra_ experiments and analyses in our work on "Robustness Analysis of Pareto-based Joint Evaluation of Fairness and Relevance in Recommender Systems", which is currently under review (single-anonymous).

This work extends the WWW'25 full paper "Joint Evaluation of Fairness and Relevance in Recommender Systems with Pareto Frontier" by Theresia Veronika Rampisela, Tuukka Ruotsalo, Maria Maistro, and Christina Lioma. The code for the original experiments is available [here](https://github.com/theresiavr/DPFR-recsys-evaluation).

Links to the WWW'25 paper and poster:

[[ACM]](https://doi.org/10.1145/3696410.3714589) [[arXiv]](https://arxiv.org/abs/2502.11921) [[poster]](https://theresiavr.github.io/assets/pdf/thewebconf25-DPFR-recsys-evaluation-poster.pdf)

# License and Terms of Usage
The code is usable under the MIT License.

# Citation


```BibTeX
@inproceedings{Rampisela2025Pareto,
author = {Rampisela, Theresia Veronika and Ruotsalo, Tuukka and Maistro, Maria and Lioma, Christina},
title = {Joint Evaluation of Fairness and Relevance in Recommender Systems with Pareto Frontier},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714589},
doi = {10.1145/3696410.3714589},
pages = {1548â€“1566},
numpages = {19},
keywords = {evaluation, fairness, pareto frontier, recommendation, relevance},
location = {Sydney NSW, Australia},
series = {WWW '25}
}
```

# Datasets, Model, Evaluation, and Experiments
Please refer to the [code repository of the WWW'25 paper](https://github.com/theresiavr/can-we-trust-recsys-fairness-evaluation) to find information on dataset downloads, preprocessing, model training, reranking, evaluation, and the experiment code for the conference paper.